{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Xllf8LepozSNybMcR8SNqUSbk2_zptW_",
      "authorship_tag": "ABX9TyM28QkjZGIAnd+pJijOmnwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arinjay11020/Capstone-Speech-Sentiment-Analysis/blob/main/ANN_on_Ravdess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YVwPrMmrgm2u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/RAVDESS mfcc (1).csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "3xemEAkShCUq",
        "outputId": "b06b1728-6844-4de5-c596-e5f970096a6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0          0          1          2          3          4  \\\n",
              "0           0 -682.78656  49.554104  -2.957227   6.492600  -4.533283   \n",
              "1           1 -698.39307  45.490097  -8.718443   4.098103 -10.368684   \n",
              "2           2 -683.54150  45.790790  -8.732436   5.652276 -10.264516   \n",
              "3           3 -510.97675  31.709919 -19.523634   1.721714 -13.628480   \n",
              "4           4 -724.06805  53.929638   0.768267  10.190290  -5.725431   \n",
              "\n",
              "          5          6          7          8  ...        32         33  \\\n",
              "0 -5.577244 -14.285715  -6.971066 -11.032431  ...  0.662825   4.226065   \n",
              "1 -3.493486 -12.813138 -12.302380 -10.428462  ...  4.723077   8.205063   \n",
              "2 -3.631711 -13.565022 -10.328115  -7.746146  ...  0.605757   1.795494   \n",
              "3 -9.110020  -9.474399  -6.853446 -10.732971  ... -0.969694   1.011588   \n",
              "4 -1.370537 -11.506711  -6.727295  -8.388384  ...  8.944055  10.673691   \n",
              "\n",
              "         34        35        36        37        38        39  Emotion  \\\n",
              "0  5.288602  6.437543  4.037335  1.342614 -0.177404 -0.844319      Sad   \n",
              "1  7.109620  6.411415  2.029982  0.944977 -1.118757 -0.619505      Sad   \n",
              "2  1.590863  3.035923 -0.856015 -3.284239 -3.686345 -0.404304  Neutral   \n",
              "3 -1.042750  1.889726 -1.276625 -2.258035 -1.863009  1.118838    Angry   \n",
              "4  7.450894  4.113879  1.462258 -0.010495 -0.115005  1.258699      Sad   \n",
              "\n",
              "   Intensity  \n",
              "0     Normal  \n",
              "1     Normal  \n",
              "2     Normal  \n",
              "3     Normal  \n",
              "4     Normal  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2f218f0-d55d-4f1d-8993-12eb209af33e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-682.78656</td>\n",
              "      <td>49.554104</td>\n",
              "      <td>-2.957227</td>\n",
              "      <td>6.492600</td>\n",
              "      <td>-4.533283</td>\n",
              "      <td>-5.577244</td>\n",
              "      <td>-14.285715</td>\n",
              "      <td>-6.971066</td>\n",
              "      <td>-11.032431</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662825</td>\n",
              "      <td>4.226065</td>\n",
              "      <td>5.288602</td>\n",
              "      <td>6.437543</td>\n",
              "      <td>4.037335</td>\n",
              "      <td>1.342614</td>\n",
              "      <td>-0.177404</td>\n",
              "      <td>-0.844319</td>\n",
              "      <td>Sad</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-698.39307</td>\n",
              "      <td>45.490097</td>\n",
              "      <td>-8.718443</td>\n",
              "      <td>4.098103</td>\n",
              "      <td>-10.368684</td>\n",
              "      <td>-3.493486</td>\n",
              "      <td>-12.813138</td>\n",
              "      <td>-12.302380</td>\n",
              "      <td>-10.428462</td>\n",
              "      <td>...</td>\n",
              "      <td>4.723077</td>\n",
              "      <td>8.205063</td>\n",
              "      <td>7.109620</td>\n",
              "      <td>6.411415</td>\n",
              "      <td>2.029982</td>\n",
              "      <td>0.944977</td>\n",
              "      <td>-1.118757</td>\n",
              "      <td>-0.619505</td>\n",
              "      <td>Sad</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-683.54150</td>\n",
              "      <td>45.790790</td>\n",
              "      <td>-8.732436</td>\n",
              "      <td>5.652276</td>\n",
              "      <td>-10.264516</td>\n",
              "      <td>-3.631711</td>\n",
              "      <td>-13.565022</td>\n",
              "      <td>-10.328115</td>\n",
              "      <td>-7.746146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.605757</td>\n",
              "      <td>1.795494</td>\n",
              "      <td>1.590863</td>\n",
              "      <td>3.035923</td>\n",
              "      <td>-0.856015</td>\n",
              "      <td>-3.284239</td>\n",
              "      <td>-3.686345</td>\n",
              "      <td>-0.404304</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-510.97675</td>\n",
              "      <td>31.709919</td>\n",
              "      <td>-19.523634</td>\n",
              "      <td>1.721714</td>\n",
              "      <td>-13.628480</td>\n",
              "      <td>-9.110020</td>\n",
              "      <td>-9.474399</td>\n",
              "      <td>-6.853446</td>\n",
              "      <td>-10.732971</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.969694</td>\n",
              "      <td>1.011588</td>\n",
              "      <td>-1.042750</td>\n",
              "      <td>1.889726</td>\n",
              "      <td>-1.276625</td>\n",
              "      <td>-2.258035</td>\n",
              "      <td>-1.863009</td>\n",
              "      <td>1.118838</td>\n",
              "      <td>Angry</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-724.06805</td>\n",
              "      <td>53.929638</td>\n",
              "      <td>0.768267</td>\n",
              "      <td>10.190290</td>\n",
              "      <td>-5.725431</td>\n",
              "      <td>-1.370537</td>\n",
              "      <td>-11.506711</td>\n",
              "      <td>-6.727295</td>\n",
              "      <td>-8.388384</td>\n",
              "      <td>...</td>\n",
              "      <td>8.944055</td>\n",
              "      <td>10.673691</td>\n",
              "      <td>7.450894</td>\n",
              "      <td>4.113879</td>\n",
              "      <td>1.462258</td>\n",
              "      <td>-0.010495</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>1.258699</td>\n",
              "      <td>Sad</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2f218f0-d55d-4f1d-8993-12eb209af33e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2f218f0-d55d-4f1d-8993-12eb209af33e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2f218f0-d55d-4f1d-8993-12eb209af33e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"Unnamed: 0\",\"Intensity\"],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "CP18PVrVhMAy",
        "outputId": "142640c1-6d6e-4408-e797-fc472831b76c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0          1          2          3          4         5          6  \\\n",
              "0 -682.78656  49.554104  -2.957227   6.492600  -4.533283 -5.577244 -14.285715   \n",
              "1 -698.39307  45.490097  -8.718443   4.098103 -10.368684 -3.493486 -12.813138   \n",
              "2 -683.54150  45.790790  -8.732436   5.652276 -10.264516 -3.631711 -13.565022   \n",
              "3 -510.97675  31.709919 -19.523634   1.721714 -13.628480 -9.110020  -9.474399   \n",
              "4 -724.06805  53.929638   0.768267  10.190290  -5.725431 -1.370537 -11.506711   \n",
              "\n",
              "           7          8         9  ...        31        32         33  \\\n",
              "0  -6.971066 -11.032431 -4.461883  ...  0.472623  0.662825   4.226065   \n",
              "1 -12.302380 -10.428462 -6.491344  ...  4.522738  4.723077   8.205063   \n",
              "2 -10.328115  -7.746146 -3.926473  ...  4.069837  0.605757   1.795494   \n",
              "3  -6.853446 -10.732971  0.213203  ...  1.484451 -0.969694   1.011588   \n",
              "4  -6.727295  -8.388384 -1.278562  ...  8.637044  8.944055  10.673691   \n",
              "\n",
              "         34        35        36        37        38        39  Emotion  \n",
              "0  5.288602  6.437543  4.037335  1.342614 -0.177404 -0.844319      Sad  \n",
              "1  7.109620  6.411415  2.029982  0.944977 -1.118757 -0.619505      Sad  \n",
              "2  1.590863  3.035923 -0.856015 -3.284239 -3.686345 -0.404304  Neutral  \n",
              "3 -1.042750  1.889726 -1.276625 -2.258035 -1.863009  1.118838    Angry  \n",
              "4  7.450894  4.113879  1.462258 -0.010495 -0.115005  1.258699      Sad  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4fb22ea-7666-43db-8c63-e277603c3643\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-682.78656</td>\n",
              "      <td>49.554104</td>\n",
              "      <td>-2.957227</td>\n",
              "      <td>6.492600</td>\n",
              "      <td>-4.533283</td>\n",
              "      <td>-5.577244</td>\n",
              "      <td>-14.285715</td>\n",
              "      <td>-6.971066</td>\n",
              "      <td>-11.032431</td>\n",
              "      <td>-4.461883</td>\n",
              "      <td>...</td>\n",
              "      <td>0.472623</td>\n",
              "      <td>0.662825</td>\n",
              "      <td>4.226065</td>\n",
              "      <td>5.288602</td>\n",
              "      <td>6.437543</td>\n",
              "      <td>4.037335</td>\n",
              "      <td>1.342614</td>\n",
              "      <td>-0.177404</td>\n",
              "      <td>-0.844319</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-698.39307</td>\n",
              "      <td>45.490097</td>\n",
              "      <td>-8.718443</td>\n",
              "      <td>4.098103</td>\n",
              "      <td>-10.368684</td>\n",
              "      <td>-3.493486</td>\n",
              "      <td>-12.813138</td>\n",
              "      <td>-12.302380</td>\n",
              "      <td>-10.428462</td>\n",
              "      <td>-6.491344</td>\n",
              "      <td>...</td>\n",
              "      <td>4.522738</td>\n",
              "      <td>4.723077</td>\n",
              "      <td>8.205063</td>\n",
              "      <td>7.109620</td>\n",
              "      <td>6.411415</td>\n",
              "      <td>2.029982</td>\n",
              "      <td>0.944977</td>\n",
              "      <td>-1.118757</td>\n",
              "      <td>-0.619505</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-683.54150</td>\n",
              "      <td>45.790790</td>\n",
              "      <td>-8.732436</td>\n",
              "      <td>5.652276</td>\n",
              "      <td>-10.264516</td>\n",
              "      <td>-3.631711</td>\n",
              "      <td>-13.565022</td>\n",
              "      <td>-10.328115</td>\n",
              "      <td>-7.746146</td>\n",
              "      <td>-3.926473</td>\n",
              "      <td>...</td>\n",
              "      <td>4.069837</td>\n",
              "      <td>0.605757</td>\n",
              "      <td>1.795494</td>\n",
              "      <td>1.590863</td>\n",
              "      <td>3.035923</td>\n",
              "      <td>-0.856015</td>\n",
              "      <td>-3.284239</td>\n",
              "      <td>-3.686345</td>\n",
              "      <td>-0.404304</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-510.97675</td>\n",
              "      <td>31.709919</td>\n",
              "      <td>-19.523634</td>\n",
              "      <td>1.721714</td>\n",
              "      <td>-13.628480</td>\n",
              "      <td>-9.110020</td>\n",
              "      <td>-9.474399</td>\n",
              "      <td>-6.853446</td>\n",
              "      <td>-10.732971</td>\n",
              "      <td>0.213203</td>\n",
              "      <td>...</td>\n",
              "      <td>1.484451</td>\n",
              "      <td>-0.969694</td>\n",
              "      <td>1.011588</td>\n",
              "      <td>-1.042750</td>\n",
              "      <td>1.889726</td>\n",
              "      <td>-1.276625</td>\n",
              "      <td>-2.258035</td>\n",
              "      <td>-1.863009</td>\n",
              "      <td>1.118838</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-724.06805</td>\n",
              "      <td>53.929638</td>\n",
              "      <td>0.768267</td>\n",
              "      <td>10.190290</td>\n",
              "      <td>-5.725431</td>\n",
              "      <td>-1.370537</td>\n",
              "      <td>-11.506711</td>\n",
              "      <td>-6.727295</td>\n",
              "      <td>-8.388384</td>\n",
              "      <td>-1.278562</td>\n",
              "      <td>...</td>\n",
              "      <td>8.637044</td>\n",
              "      <td>8.944055</td>\n",
              "      <td>10.673691</td>\n",
              "      <td>7.450894</td>\n",
              "      <td>4.113879</td>\n",
              "      <td>1.462258</td>\n",
              "      <td>-0.010495</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>1.258699</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4fb22ea-7666-43db-8c63-e277603c3643')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4fb22ea-7666-43db-8c63-e277603c3643 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4fb22ea-7666-43db-8c63-e277603c3643');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Emotion\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8s55653hsQo",
        "outputId": "1164c6d5-0994-4ae1-fcf3-4c1bcef5e459"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sad', 'Neutral', 'Angry', 'Happy', 'Disgust', 'Calm', 'Fearful',\n",
              "       'Surprised'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "Y=to_categorical(labelencoder.fit_transform(df[\"Emotion\"]))"
      ],
      "metadata": {
        "id": "HbYNsTT4hUka"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "QfYKeTsEhw7c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(df.iloc[:,:-1],Y,test_size=0.1,random_state=10)"
      ],
      "metadata": {
        "id": "Wy9A8dadh3Ll"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G6MMbdaiBBm",
        "outputId": "fd56bc44-15a6-4500-c8bf-e5fe1104d782"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 40) (576, 40) (5184, 8) (576, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(34,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.4))\n",
        "##second layer\n",
        "model.add(Dense(34))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.4))\n",
        "###third layer\n",
        "model.add(Dense(34))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.4))\n",
        "\n",
        "###final layer\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "St9Sv3JxiF6s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3HnVovQiN_R",
        "outputId": "e0bcb0c6-36a1-4250-fc3d-5d08b121e267"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 34)                1394      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 34)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                1190      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 34)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 34)                1190      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 34)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 280       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,054\n",
            "Trainable params: 4,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "metadata": {
        "id": "6rrt7EBRiSGf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 100\n",
        "num_batch_size = 8\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='ann_ravdess.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, Y_test), callbacks=[checkpointer], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3BQxJoqiXBt",
        "outputId": "6da2eb90-3af1-4f2b-fffb-d9d4d6a947c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "641/648 [============================>.] - ETA: 0s - loss: 2.9695 - accuracy: 0.2067\n",
            "Epoch 1: val_loss improved from inf to 2.02509, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 3s 3ms/step - loss: 2.9642 - accuracy: 0.2056 - val_loss: 2.0251 - val_accuracy: 0.2674\n",
            "Epoch 2/100\n",
            "633/648 [============================>.] - ETA: 0s - loss: 2.0050 - accuracy: 0.3047\n",
            "Epoch 2: val_loss did not improve from 2.02509\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 2.0116 - accuracy: 0.3030 - val_loss: 2.1413 - val_accuracy: 0.2691\n",
            "Epoch 3/100\n",
            "637/648 [============================>.] - ETA: 0s - loss: 1.8362 - accuracy: 0.3340\n",
            "Epoch 3: val_loss improved from 2.02509 to 1.73256, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.8384 - accuracy: 0.3337 - val_loss: 1.7326 - val_accuracy: 0.3819\n",
            "Epoch 4/100\n",
            "643/648 [============================>.] - ETA: 0s - loss: 1.7478 - accuracy: 0.3733\n",
            "Epoch 4: val_loss improved from 1.73256 to 1.64452, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.7451 - accuracy: 0.3748 - val_loss: 1.6445 - val_accuracy: 0.4167\n",
            "Epoch 5/100\n",
            "640/648 [============================>.] - ETA: 0s - loss: 1.7098 - accuracy: 0.3723\n",
            "Epoch 5: val_loss did not improve from 1.64452\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.7099 - accuracy: 0.3723 - val_loss: 1.6814 - val_accuracy: 0.3785\n",
            "Epoch 6/100\n",
            "647/648 [============================>.] - ETA: 0s - loss: 1.6546 - accuracy: 0.3908\n",
            "Epoch 6: val_loss did not improve from 1.64452\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.6547 - accuracy: 0.3910 - val_loss: 1.7027 - val_accuracy: 0.3681\n",
            "Epoch 7/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 1.5920 - accuracy: 0.4104\n",
            "Epoch 7: val_loss did not improve from 1.64452\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.5942 - accuracy: 0.4097 - val_loss: 1.7275 - val_accuracy: 0.3507\n",
            "Epoch 8/100\n",
            "621/648 [===========================>..] - ETA: 0s - loss: 1.5637 - accuracy: 0.4169\n",
            "Epoch 8: val_loss improved from 1.64452 to 1.51813, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.5698 - accuracy: 0.4140 - val_loss: 1.5181 - val_accuracy: 0.4253\n",
            "Epoch 9/100\n",
            "644/648 [============================>.] - ETA: 0s - loss: 1.5250 - accuracy: 0.4309\n",
            "Epoch 9: val_loss improved from 1.51813 to 1.48277, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.5241 - accuracy: 0.4311 - val_loss: 1.4828 - val_accuracy: 0.4236\n",
            "Epoch 10/100\n",
            "631/648 [============================>.] - ETA: 0s - loss: 1.5014 - accuracy: 0.4455\n",
            "Epoch 10: val_loss did not improve from 1.48277\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.5088 - accuracy: 0.4435 - val_loss: 1.5908 - val_accuracy: 0.4201\n",
            "Epoch 11/100\n",
            "635/648 [============================>.] - ETA: 0s - loss: 1.4869 - accuracy: 0.4470\n",
            "Epoch 11: val_loss improved from 1.48277 to 1.45764, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.4864 - accuracy: 0.4462 - val_loss: 1.4576 - val_accuracy: 0.4410\n",
            "Epoch 12/100\n",
            "630/648 [============================>.] - ETA: 0s - loss: 1.4498 - accuracy: 0.4631\n",
            "Epoch 12: val_loss improved from 1.45764 to 1.45467, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.4479 - accuracy: 0.4639 - val_loss: 1.4547 - val_accuracy: 0.4792\n",
            "Epoch 13/100\n",
            "638/648 [============================>.] - ETA: 0s - loss: 1.4307 - accuracy: 0.4716\n",
            "Epoch 13: val_loss did not improve from 1.45467\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.4317 - accuracy: 0.4716 - val_loss: 1.5979 - val_accuracy: 0.3733\n",
            "Epoch 14/100\n",
            "636/648 [============================>.] - ETA: 0s - loss: 1.4052 - accuracy: 0.4778\n",
            "Epoch 14: val_loss did not improve from 1.45467\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.4056 - accuracy: 0.4786 - val_loss: 1.5621 - val_accuracy: 0.4115\n",
            "Epoch 15/100\n",
            "646/648 [============================>.] - ETA: 0s - loss: 1.3887 - accuracy: 0.4836\n",
            "Epoch 15: val_loss improved from 1.45467 to 1.38051, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.3874 - accuracy: 0.4838 - val_loss: 1.3805 - val_accuracy: 0.4931\n",
            "Epoch 16/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 1.3617 - accuracy: 0.4848\n",
            "Epoch 16: val_loss did not improve from 1.38051\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.3617 - accuracy: 0.4848 - val_loss: 1.3996 - val_accuracy: 0.4566\n",
            "Epoch 17/100\n",
            "634/648 [============================>.] - ETA: 0s - loss: 1.3284 - accuracy: 0.5069\n",
            "Epoch 17: val_loss improved from 1.38051 to 1.37277, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.3295 - accuracy: 0.5064 - val_loss: 1.3728 - val_accuracy: 0.5017\n",
            "Epoch 18/100\n",
            "624/648 [===========================>..] - ETA: 0s - loss: 1.2981 - accuracy: 0.5170\n",
            "Epoch 18: val_loss improved from 1.37277 to 1.30036, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.2989 - accuracy: 0.5162 - val_loss: 1.3004 - val_accuracy: 0.5104\n",
            "Epoch 19/100\n",
            "627/648 [============================>.] - ETA: 0s - loss: 1.2655 - accuracy: 0.5287\n",
            "Epoch 19: val_loss did not improve from 1.30036\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.2689 - accuracy: 0.5268 - val_loss: 1.3093 - val_accuracy: 0.5035\n",
            "Epoch 20/100\n",
            "621/648 [===========================>..] - ETA: 0s - loss: 1.2478 - accuracy: 0.5372\n",
            "Epoch 20: val_loss did not improve from 1.30036\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.2519 - accuracy: 0.5368 - val_loss: 1.3043 - val_accuracy: 0.5174\n",
            "Epoch 21/100\n",
            "637/648 [============================>.] - ETA: 0s - loss: 1.2210 - accuracy: 0.5481\n",
            "Epoch 21: val_loss did not improve from 1.30036\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 1.2184 - accuracy: 0.5496 - val_loss: 1.3221 - val_accuracy: 0.5156\n",
            "Epoch 22/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 1.2155 - accuracy: 0.5403\n",
            "Epoch 22: val_loss improved from 1.30036 to 1.29290, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 1.2155 - accuracy: 0.5403 - val_loss: 1.2929 - val_accuracy: 0.5191\n",
            "Epoch 23/100\n",
            "637/648 [============================>.] - ETA: 0s - loss: 1.1853 - accuracy: 0.5600\n",
            "Epoch 23: val_loss improved from 1.29290 to 1.26090, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 1.1861 - accuracy: 0.5604 - val_loss: 1.2609 - val_accuracy: 0.5399\n",
            "Epoch 24/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 1.1495 - accuracy: 0.5700\n",
            "Epoch 24: val_loss improved from 1.26090 to 1.20626, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.1472 - accuracy: 0.5696 - val_loss: 1.2063 - val_accuracy: 0.5382\n",
            "Epoch 25/100\n",
            "638/648 [============================>.] - ETA: 0s - loss: 1.1428 - accuracy: 0.5825\n",
            "Epoch 25: val_loss improved from 1.20626 to 1.18678, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.1439 - accuracy: 0.5818 - val_loss: 1.1868 - val_accuracy: 0.5556\n",
            "Epoch 26/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 1.1127 - accuracy: 0.5796\n",
            "Epoch 26: val_loss improved from 1.18678 to 1.18171, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.1130 - accuracy: 0.5789 - val_loss: 1.1817 - val_accuracy: 0.5625\n",
            "Epoch 27/100\n",
            "631/648 [============================>.] - ETA: 0s - loss: 1.0811 - accuracy: 0.6014\n",
            "Epoch 27: val_loss did not improve from 1.18171\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.0828 - accuracy: 0.5995 - val_loss: 1.1823 - val_accuracy: 0.5625\n",
            "Epoch 28/100\n",
            "624/648 [===========================>..] - ETA: 0s - loss: 1.0906 - accuracy: 0.5907\n",
            "Epoch 28: val_loss improved from 1.18171 to 1.17924, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.0863 - accuracy: 0.5941 - val_loss: 1.1792 - val_accuracy: 0.5486\n",
            "Epoch 29/100\n",
            "634/648 [============================>.] - ETA: 0s - loss: 1.0417 - accuracy: 0.6209\n",
            "Epoch 29: val_loss improved from 1.17924 to 1.11634, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.0434 - accuracy: 0.6188 - val_loss: 1.1163 - val_accuracy: 0.5903\n",
            "Epoch 30/100\n",
            "642/648 [============================>.] - ETA: 0s - loss: 1.0379 - accuracy: 0.6199\n",
            "Epoch 30: val_loss improved from 1.11634 to 1.11528, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.0348 - accuracy: 0.6217 - val_loss: 1.1153 - val_accuracy: 0.6042\n",
            "Epoch 31/100\n",
            "626/648 [===========================>..] - ETA: 0s - loss: 1.0240 - accuracy: 0.6252\n",
            "Epoch 31: val_loss did not improve from 1.11528\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.0246 - accuracy: 0.6256 - val_loss: 1.1945 - val_accuracy: 0.5660\n",
            "Epoch 32/100\n",
            "626/648 [===========================>..] - ETA: 0s - loss: 0.9976 - accuracy: 0.6276\n",
            "Epoch 32: val_loss improved from 1.11528 to 1.07370, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 1.0009 - accuracy: 0.6281 - val_loss: 1.0737 - val_accuracy: 0.6233\n",
            "Epoch 33/100\n",
            "639/648 [============================>.] - ETA: 0s - loss: 0.9703 - accuracy: 0.6426\n",
            "Epoch 33: val_loss did not improve from 1.07370\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.9681 - accuracy: 0.6431 - val_loss: 1.0859 - val_accuracy: 0.6181\n",
            "Epoch 34/100\n",
            "635/648 [============================>.] - ETA: 0s - loss: 0.9507 - accuracy: 0.6557\n",
            "Epoch 34: val_loss improved from 1.07370 to 1.00535, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.9499 - accuracy: 0.6561 - val_loss: 1.0053 - val_accuracy: 0.6319\n",
            "Epoch 35/100\n",
            "624/648 [===========================>..] - ETA: 0s - loss: 0.9574 - accuracy: 0.6424\n",
            "Epoch 35: val_loss did not improve from 1.00535\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.9565 - accuracy: 0.6429 - val_loss: 1.1111 - val_accuracy: 0.5920\n",
            "Epoch 36/100\n",
            "644/648 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.6541\n",
            "Epoch 36: val_loss improved from 1.00535 to 0.96821, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.9286 - accuracy: 0.6543 - val_loss: 0.9682 - val_accuracy: 0.6441\n",
            "Epoch 37/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 0.9090 - accuracy: 0.6644\n",
            "Epoch 37: val_loss did not improve from 0.96821\n",
            "648/648 [==============================] - 3s 5ms/step - loss: 0.9090 - accuracy: 0.6644 - val_loss: 1.0689 - val_accuracy: 0.6076\n",
            "Epoch 38/100\n",
            "638/648 [============================>.] - ETA: 0s - loss: 0.8978 - accuracy: 0.6681\n",
            "Epoch 38: val_loss did not improve from 0.96821\n",
            "648/648 [==============================] - 3s 5ms/step - loss: 0.8989 - accuracy: 0.6684 - val_loss: 1.0576 - val_accuracy: 0.6059\n",
            "Epoch 39/100\n",
            "636/648 [============================>.] - ETA: 0s - loss: 0.8803 - accuracy: 0.6763\n",
            "Epoch 39: val_loss did not improve from 0.96821\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8840 - accuracy: 0.6753 - val_loss: 0.9813 - val_accuracy: 0.6510\n",
            "Epoch 40/100\n",
            "642/648 [============================>.] - ETA: 0s - loss: 0.8745 - accuracy: 0.6799\n",
            "Epoch 40: val_loss improved from 0.96821 to 0.95749, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8754 - accuracy: 0.6798 - val_loss: 0.9575 - val_accuracy: 0.6302\n",
            "Epoch 41/100\n",
            "643/648 [============================>.] - ETA: 0s - loss: 0.8652 - accuracy: 0.6783\n",
            "Epoch 41: val_loss did not improve from 0.95749\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8646 - accuracy: 0.6779 - val_loss: 0.9770 - val_accuracy: 0.6562\n",
            "Epoch 42/100\n",
            "646/648 [============================>.] - ETA: 0s - loss: 0.8516 - accuracy: 0.6873\n",
            "Epoch 42: val_loss did not improve from 0.95749\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8504 - accuracy: 0.6879 - val_loss: 1.0112 - val_accuracy: 0.6441\n",
            "Epoch 43/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 0.8244 - accuracy: 0.6916\n",
            "Epoch 43: val_loss did not improve from 0.95749\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8244 - accuracy: 0.6916 - val_loss: 1.0145 - val_accuracy: 0.6406\n",
            "Epoch 44/100\n",
            "633/648 [============================>.] - ETA: 0s - loss: 0.8186 - accuracy: 0.6963\n",
            "Epoch 44: val_loss did not improve from 0.95749\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8204 - accuracy: 0.6966 - val_loss: 1.0819 - val_accuracy: 0.6146\n",
            "Epoch 45/100\n",
            "623/648 [===========================>..] - ETA: 0s - loss: 0.8116 - accuracy: 0.6990\n",
            "Epoch 45: val_loss improved from 0.95749 to 0.94238, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8079 - accuracy: 0.6998 - val_loss: 0.9424 - val_accuracy: 0.6510\n",
            "Epoch 46/100\n",
            "639/648 [============================>.] - ETA: 0s - loss: 0.8220 - accuracy: 0.6948\n",
            "Epoch 46: val_loss improved from 0.94238 to 0.90031, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.8207 - accuracy: 0.6950 - val_loss: 0.9003 - val_accuracy: 0.6632\n",
            "Epoch 47/100\n",
            "634/648 [============================>.] - ETA: 0s - loss: 0.7797 - accuracy: 0.7086\n",
            "Epoch 47: val_loss did not improve from 0.90031\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.7780 - accuracy: 0.7089 - val_loss: 1.0804 - val_accuracy: 0.6250\n",
            "Epoch 48/100\n",
            "643/648 [============================>.] - ETA: 0s - loss: 0.7785 - accuracy: 0.7105\n",
            "Epoch 48: val_loss improved from 0.90031 to 0.85913, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.7780 - accuracy: 0.7108 - val_loss: 0.8591 - val_accuracy: 0.6788\n",
            "Epoch 49/100\n",
            "643/648 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.7245\n",
            "Epoch 49: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.7566 - accuracy: 0.7249 - val_loss: 0.9558 - val_accuracy: 0.6736\n",
            "Epoch 50/100\n",
            "633/648 [============================>.] - ETA: 0s - loss: 0.7539 - accuracy: 0.7224\n",
            "Epoch 50: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.7523 - accuracy: 0.7224 - val_loss: 1.0460 - val_accuracy: 0.6510\n",
            "Epoch 51/100\n",
            "646/648 [============================>.] - ETA: 0s - loss: 0.7375 - accuracy: 0.7283\n",
            "Epoch 51: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.7376 - accuracy: 0.7280 - val_loss: 0.9119 - val_accuracy: 0.6701\n",
            "Epoch 52/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 0.7215 - accuracy: 0.7380\n",
            "Epoch 52: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.7215 - accuracy: 0.7380 - val_loss: 1.0221 - val_accuracy: 0.6424\n",
            "Epoch 53/100\n",
            "646/648 [============================>.] - ETA: 0s - loss: 0.7282 - accuracy: 0.7334\n",
            "Epoch 53: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.7276 - accuracy: 0.7336 - val_loss: 0.9269 - val_accuracy: 0.6771\n",
            "Epoch 54/100\n",
            "637/648 [============================>.] - ETA: 0s - loss: 0.7034 - accuracy: 0.7453\n",
            "Epoch 54: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.7047 - accuracy: 0.7444 - val_loss: 0.8897 - val_accuracy: 0.6875\n",
            "Epoch 55/100\n",
            "634/648 [============================>.] - ETA: 0s - loss: 0.7081 - accuracy: 0.7390\n",
            "Epoch 55: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.7097 - accuracy: 0.7384 - val_loss: 0.8964 - val_accuracy: 0.6910\n",
            "Epoch 56/100\n",
            "647/648 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.7479\n",
            "Epoch 56: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.7477 - val_loss: 0.9422 - val_accuracy: 0.6736\n",
            "Epoch 57/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 0.6968 - accuracy: 0.7400\n",
            "Epoch 57: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6956 - accuracy: 0.7400 - val_loss: 0.9993 - val_accuracy: 0.6441\n",
            "Epoch 58/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7459\n",
            "Epoch 58: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6772 - accuracy: 0.7459 - val_loss: 0.8869 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "641/648 [============================>.] - ETA: 0s - loss: 0.6746 - accuracy: 0.7502\n",
            "Epoch 59: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6760 - accuracy: 0.7496 - val_loss: 0.8692 - val_accuracy: 0.6892\n",
            "Epoch 60/100\n",
            "630/648 [============================>.] - ETA: 0s - loss: 0.6575 - accuracy: 0.7597\n",
            "Epoch 60: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.6596 - accuracy: 0.7595 - val_loss: 0.9681 - val_accuracy: 0.6615\n",
            "Epoch 61/100\n",
            "632/648 [============================>.] - ETA: 0s - loss: 0.6671 - accuracy: 0.7528\n",
            "Epoch 61: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6674 - accuracy: 0.7537 - val_loss: 0.8640 - val_accuracy: 0.7049\n",
            "Epoch 62/100\n",
            "627/648 [============================>.] - ETA: 0s - loss: 0.6595 - accuracy: 0.7562\n",
            "Epoch 62: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6602 - accuracy: 0.7562 - val_loss: 0.9830 - val_accuracy: 0.6476\n",
            "Epoch 63/100\n",
            "638/648 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.7623\n",
            "Epoch 63: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.6504 - accuracy: 0.7622 - val_loss: 0.9525 - val_accuracy: 0.6649\n",
            "Epoch 64/100\n",
            "642/648 [============================>.] - ETA: 0s - loss: 0.6323 - accuracy: 0.7710\n",
            "Epoch 64: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6337 - accuracy: 0.7703 - val_loss: 0.9102 - val_accuracy: 0.6979\n",
            "Epoch 65/100\n",
            "639/648 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.7705\n",
            "Epoch 65: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6279 - accuracy: 0.7712 - val_loss: 0.9478 - val_accuracy: 0.6997\n",
            "Epoch 66/100\n",
            "621/648 [===========================>..] - ETA: 0s - loss: 0.6410 - accuracy: 0.7683\n",
            "Epoch 66: val_loss did not improve from 0.85913\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.6435 - accuracy: 0.7670 - val_loss: 0.8596 - val_accuracy: 0.6771\n",
            "Epoch 67/100\n",
            "628/648 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.7693\n",
            "Epoch 67: val_loss improved from 0.85913 to 0.82669, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.6157 - accuracy: 0.7689 - val_loss: 0.8267 - val_accuracy: 0.7066\n",
            "Epoch 68/100\n",
            "641/648 [============================>.] - ETA: 0s - loss: 0.6259 - accuracy: 0.7691\n",
            "Epoch 68: val_loss did not improve from 0.82669\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6242 - accuracy: 0.7701 - val_loss: 0.8770 - val_accuracy: 0.6771\n",
            "Epoch 69/100\n",
            "647/648 [============================>.] - ETA: 0s - loss: 0.6248 - accuracy: 0.7703\n",
            "Epoch 69: val_loss did not improve from 0.82669\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.6240 - accuracy: 0.7706 - val_loss: 0.8993 - val_accuracy: 0.6823\n",
            "Epoch 70/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 0.6196 - accuracy: 0.7784\n",
            "Epoch 70: val_loss did not improve from 0.82669\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.6211 - accuracy: 0.7776 - val_loss: 0.8437 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "630/648 [============================>.] - ETA: 0s - loss: 0.5933 - accuracy: 0.7758\n",
            "Epoch 71: val_loss did not improve from 0.82669\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5936 - accuracy: 0.7758 - val_loss: 0.8892 - val_accuracy: 0.6806\n",
            "Epoch 72/100\n",
            "626/648 [===========================>..] - ETA: 0s - loss: 0.5977 - accuracy: 0.7782\n",
            "Epoch 72: val_loss did not improve from 0.82669\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.6002 - accuracy: 0.7791 - val_loss: 0.9297 - val_accuracy: 0.7135\n",
            "Epoch 73/100\n",
            "639/648 [============================>.] - ETA: 0s - loss: 0.5852 - accuracy: 0.7881\n",
            "Epoch 73: val_loss did not improve from 0.82669\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5872 - accuracy: 0.7872 - val_loss: 1.0014 - val_accuracy: 0.6788\n",
            "Epoch 74/100\n",
            "629/648 [============================>.] - ETA: 0s - loss: 0.5818 - accuracy: 0.7848\n",
            "Epoch 74: val_loss improved from 0.82669 to 0.79723, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5821 - accuracy: 0.7841 - val_loss: 0.7972 - val_accuracy: 0.7135\n",
            "Epoch 75/100\n",
            "643/648 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.7871\n",
            "Epoch 75: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5820 - accuracy: 0.7865 - val_loss: 0.9391 - val_accuracy: 0.7083\n",
            "Epoch 76/100\n",
            "626/648 [===========================>..] - ETA: 0s - loss: 0.5928 - accuracy: 0.7823\n",
            "Epoch 76: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7812 - val_loss: 0.8277 - val_accuracy: 0.7292\n",
            "Epoch 77/100\n",
            "641/648 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.7966\n",
            "Epoch 77: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5653 - accuracy: 0.7949 - val_loss: 0.8408 - val_accuracy: 0.7257\n",
            "Epoch 78/100\n",
            "629/648 [============================>.] - ETA: 0s - loss: 0.5930 - accuracy: 0.7804\n",
            "Epoch 78: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.7809 - val_loss: 0.8779 - val_accuracy: 0.7014\n",
            "Epoch 79/100\n",
            "646/648 [============================>.] - ETA: 0s - loss: 0.5719 - accuracy: 0.7928\n",
            "Epoch 79: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7930 - val_loss: 1.0723 - val_accuracy: 0.6701\n",
            "Epoch 80/100\n",
            "640/648 [============================>.] - ETA: 0s - loss: 0.5699 - accuracy: 0.7922\n",
            "Epoch 80: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5690 - accuracy: 0.7932 - val_loss: 0.8019 - val_accuracy: 0.7083\n",
            "Epoch 81/100\n",
            "628/648 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.7872\n",
            "Epoch 81: val_loss did not improve from 0.79723\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.5711 - accuracy: 0.7890 - val_loss: 0.7986 - val_accuracy: 0.7257\n",
            "Epoch 82/100\n",
            "642/648 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.8037\n",
            "Epoch 82: val_loss improved from 0.79723 to 0.76140, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.8030 - val_loss: 0.7614 - val_accuracy: 0.7205\n",
            "Epoch 83/100\n",
            "632/648 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.7979\n",
            "Epoch 83: val_loss did not improve from 0.76140\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5611 - accuracy: 0.7982 - val_loss: 0.8263 - val_accuracy: 0.7326\n",
            "Epoch 84/100\n",
            "648/648 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7917\n",
            "Epoch 84: val_loss did not improve from 0.76140\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7917 - val_loss: 0.7943 - val_accuracy: 0.7222\n",
            "Epoch 85/100\n",
            "623/648 [===========================>..] - ETA: 0s - loss: 0.5194 - accuracy: 0.8112\n",
            "Epoch 85: val_loss improved from 0.76140 to 0.74499, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5226 - accuracy: 0.8098 - val_loss: 0.7450 - val_accuracy: 0.7378\n",
            "Epoch 86/100\n",
            "630/648 [============================>.] - ETA: 0s - loss: 0.5430 - accuracy: 0.8008\n",
            "Epoch 86: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.8003 - val_loss: 0.9256 - val_accuracy: 0.6997\n",
            "Epoch 87/100\n",
            "627/648 [============================>.] - ETA: 0s - loss: 0.5567 - accuracy: 0.8006\n",
            "Epoch 87: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5554 - accuracy: 0.8011 - val_loss: 0.7759 - val_accuracy: 0.7292\n",
            "Epoch 88/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 0.5287 - accuracy: 0.8070\n",
            "Epoch 88: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.8083 - val_loss: 0.9404 - val_accuracy: 0.7083\n",
            "Epoch 89/100\n",
            "634/648 [============================>.] - ETA: 0s - loss: 0.5251 - accuracy: 0.8078\n",
            "Epoch 89: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5267 - accuracy: 0.8083 - val_loss: 0.7935 - val_accuracy: 0.7135\n",
            "Epoch 90/100\n",
            "638/648 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.7998\n",
            "Epoch 90: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7988 - val_loss: 0.7714 - val_accuracy: 0.7431\n",
            "Epoch 91/100\n",
            "645/648 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.8002\n",
            "Epoch 91: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.8003 - val_loss: 0.8580 - val_accuracy: 0.7083\n",
            "Epoch 92/100\n",
            "626/648 [===========================>..] - ETA: 0s - loss: 0.5052 - accuracy: 0.8141\n",
            "Epoch 92: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.8148 - val_loss: 0.7799 - val_accuracy: 0.7483\n",
            "Epoch 93/100\n",
            "631/648 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.8086\n",
            "Epoch 93: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.8079 - val_loss: 0.8320 - val_accuracy: 0.7257\n",
            "Epoch 94/100\n",
            "635/648 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.8035\n",
            "Epoch 94: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.8040 - val_loss: 0.8308 - val_accuracy: 0.7344\n",
            "Epoch 95/100\n",
            "623/648 [===========================>..] - ETA: 0s - loss: 0.5166 - accuracy: 0.8146\n",
            "Epoch 95: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.8142 - val_loss: 0.8182 - val_accuracy: 0.7378\n",
            "Epoch 96/100\n",
            "638/648 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.8053\n",
            "Epoch 96: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.8059 - val_loss: 0.7995 - val_accuracy: 0.7118\n",
            "Epoch 97/100\n",
            "644/648 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.8146\n",
            "Epoch 97: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.8148 - val_loss: 0.9876 - val_accuracy: 0.6927\n",
            "Epoch 98/100\n",
            "624/648 [===========================>..] - ETA: 0s - loss: 0.4955 - accuracy: 0.8127\n",
            "Epoch 98: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.4940 - accuracy: 0.8148 - val_loss: 0.7887 - val_accuracy: 0.7222\n",
            "Epoch 99/100\n",
            "625/648 [===========================>..] - ETA: 0s - loss: 0.5300 - accuracy: 0.8126\n",
            "Epoch 99: val_loss did not improve from 0.74499\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.8111 - val_loss: 0.9046 - val_accuracy: 0.7118\n",
            "Epoch 100/100\n",
            "631/648 [============================>.] - ETA: 0s - loss: 0.4918 - accuracy: 0.8205\n",
            "Epoch 100: val_loss improved from 0.74499 to 0.71896, saving model to ann_ravdess.hdf5\n",
            "648/648 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.8208 - val_loss: 0.7190 - val_accuracy: 0.7431\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae9d912890>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAPhVP2iiis8"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}